{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pytorch_mlp_binary_classification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOryW0YodXrVSRmivhVdqR4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dipanshuhaldar/binary_classification_pytorch/blob/master/pytorch_mlp_binary_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xHj1s7te_WyR",
        "colab_type": "text"
      },
      "source": [
        "* We will use the [**Ionosphere binary (two class) classification dataset**](https://archive.ics.uci.edu/ml/machine-learning-databases/ionosphere/) to demonstrate an MLP for binary classification.\n",
        "* This dataset involves predicting whether there is a structure in the atmosphere or not given radar returns."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W8IzHxfDa2rn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "outputId": "85cfad81-26e5-4d42-f98e-e4d7393e3c0d"
      },
      "source": [
        "'''\n",
        "set working directory\n",
        "look in the files in the working directory\n",
        "'''\n",
        "#mounting google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qanYU5f-_Kbc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#requirements\n",
        "from numpy import vstack\n",
        "from pandas import read_csv\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uPMxvhR2HQBl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#requirements(PyTorch)\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import random_split\n",
        "from torch import Tensor\n",
        "from torch.nn import Linear\n",
        "from torch.nn import ReLU\n",
        "from torch.nn import Sigmoid\n",
        "from torch.nn import Module\n",
        "from torch.optim import SGD\n",
        "from torch.nn import BCELoss\n",
        "from torch.nn.init import kaiming_uniform_\n",
        "from torch.nn.init import xavier_uniform_"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6FzisFsUI5PG",
        "colab_type": "text"
      },
      "source": [
        "**Loading and Data Preparation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZAzlHmYGIlbz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#dataset definition\n",
        "class CSVDataset(Dataset):\n",
        "\n",
        "  #load the data set\n",
        "    def __init__(self, path):\n",
        "      #load the data set\n",
        "      df = read_csv(path)\n",
        "      #store the features and the target\n",
        "      self.X = df.values[:, df.columns != 'Class']#desection on column name, here Class\n",
        "      self.y = df.values[:, df.columns == 'Class']#selection based on column name, here Class\n",
        "      #ensure input data is floats\n",
        "      self.X = self.X.astype('float32')\n",
        "      #label encode target and ensure the values are floats\n",
        "      self.y = LabelEncoder().fit_transform(self.y)\n",
        "      self.y = self.y.astype('float32')\n",
        "      self.y = self.y.reshape((len(self.y), 1))\n",
        "\n",
        "    #number of rows in the dataset\n",
        "    def __len__(self):\n",
        "      return len(self.X)\n",
        "\n",
        "    #get a row by index\n",
        "    def __getitem__(self, idx):\n",
        "      return [self.X[idx], self.y[idx]]\n",
        "\n",
        "    #get indexes for train and test rows\n",
        "    def get_splits(self, n_test=0.33):\n",
        "        # determine sizes\n",
        "        test_size = round(n_test * len(self.X))\n",
        "        train_size = len(self.X) - test_size\n",
        "        # calculate the split\n",
        "        return random_split(self, [train_size, test_size])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ASG9bVDZqavI",
        "colab_type": "text"
      },
      "source": [
        "**Define MLP Model Framework**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-K2_J-0hl-7o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MLP(Module):\n",
        "\n",
        "  #define model elements\n",
        "  def __init__(self, n_inputs):\n",
        "    super(MLP, self).__init__()\n",
        "\n",
        "    #input to first hidden layer\n",
        "    self.hidden1 = Linear(n_inputs, 10)\n",
        "    kaiming_uniform_(self.hidden1.weight, nonlinearity = 'relu')\n",
        "    self.act1 = ReLU()\n",
        "\n",
        "    #input to second hidden layer\n",
        "    self.hidden2 = Linear(10, 8)\n",
        "    kaiming_uniform_(self.hidden2.weight, nonlinearity = 'relu')\n",
        "    self.act2 = ReLU()\n",
        "\n",
        "    #input to third hidden layer and output\n",
        "    self.hidden3 = Linear(8, 1)\n",
        "    kaiming_uniform_(self.hidden3.weight)\n",
        "    self.act3 = Sigmoid()\n",
        "\n",
        "  #forward propagate input\n",
        "  def forward(self, X):\n",
        "    \n",
        "    #input to first hidden layer\n",
        "    X = self.hidden1(X)\n",
        "    X = self.act1(X)\n",
        "\n",
        "    #second hidden layer      \n",
        "    X = self.hidden2(X)\n",
        "    X = self.act2(X)\n",
        "\n",
        "    #third hidden ayer and output\n",
        "    X = self.hidden3(X)\n",
        "    X = self.act3(X)\n",
        "\n",
        "    return X"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CXY6szfetmxJ",
        "colab_type": "text"
      },
      "source": [
        "**Dataset Preparation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D-5--6-xnCEy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def prepare_data(path):\n",
        "\n",
        "  #load dataset\n",
        "  dataset = CSVDataset(path)\n",
        "\n",
        "  #split calculation\n",
        "  train, test = dataset.get_splits()\n",
        "\n",
        "  #prepare data loaders\n",
        "  train_dl = DataLoader(train, batch_size = 32, shuffle = True)\n",
        "  test_dl = DataLoader(test, batch_size = 1024, shuffle = False)\n",
        "\n",
        "  return train_dl, test_dl"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6xDPIwnJxXoG",
        "colab_type": "text"
      },
      "source": [
        "**Train MLP Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dmBO_KdZxaX6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_model(train_dl, model):\n",
        "\n",
        "  #define optimization\n",
        "  criterion = BCELoss()\n",
        "  optimizer = SGD(model.parameters(), lr = 0.01, momentum = 0.9)\n",
        "\n",
        "  #enumerate epochs\n",
        "  epochs = 100\n",
        "  for epoch in range(epochs):\n",
        "    #enumerate mini batches\n",
        "    for idx, (inputs, targets) in enumerate(train_dl):\n",
        "      #clear the gradients\n",
        "      optimizer.zero_grad()\n",
        "      #compute model output\n",
        "      yhat = model(inputs)\n",
        "      #calculate loss\n",
        "      loss = criterion(yhat, targets)\n",
        "      #back propagation\n",
        "      loss.backward()\n",
        "      #update model weights\n",
        "      optimizer.step() "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3wv9WzOwzlCB",
        "colab_type": "text"
      },
      "source": [
        "**Model Evaluation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-i_TMHRzn1F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate_model(test_dl, model):\n",
        "\n",
        "  predictions, actuals = list(), list()\n",
        "  for idx, (inputs, targets) in enumerate(test_dl):\n",
        "    #evaluate model on test set\n",
        "    yhat = model(inputs)\n",
        "    #retrieve numpy array\n",
        "    yhat = yhat.detach().numpy()\n",
        "    actual = targets.numpy()\n",
        "    actual = actual.reshape((len(actual), 1))\n",
        "    #round to class values\n",
        "    yhat = yhat.round()\n",
        "    #store the predicted and actuals in the empty lists\n",
        "    predictions.append(yhat)\n",
        "    actuals.append(actual)\n",
        "\n",
        "  predictions, actuals  = vstack(predictions), vstack(actuals)\n",
        "  #calculate accuracy\n",
        "  acc = accuracy_score(actuals, predictions)\n",
        "  return acc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4HeEjaTZ1afi",
        "colab_type": "text"
      },
      "source": [
        "**Make Prediction for Single Data Instance**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yNxNccoD1jZ7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict(row, model):\n",
        "\n",
        "  #convert row to Tensor\n",
        "  row = Tensor([row])\n",
        "  #make prediction\n",
        "  yhat = model(row)\n",
        "  #retrieve numpy array\n",
        "  yhat = yhat.detach().numpy()\n",
        "  return yhat.round()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "julN-r1U2Ksp",
        "colab_type": "text"
      },
      "source": [
        "**Code Run**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e8vpCK2ea3jb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "4db642e0-b0db-4089-be8f-5e117f2b0b60"
      },
      "source": [
        "import os\n",
        "path = '/content/drive/My Drive/ionosphere/'\n",
        "os.chdir(path)\n",
        "os.listdir(path)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Ionosphere.csv',\n",
              " 'original_code.ipynb',\n",
              " 'pytorch_mlp_binary_classification.ipynb']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ClWqh-Ct2P9l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "outputId": "76dd6080-11c2-4ea0-bc0b-8ea79d03035c"
      },
      "source": [
        "data_path = path + 'Ionosphere.csv'\n",
        "#prepare data\n",
        "train_dl, test_dl = prepare_data(data_path)\n",
        "print(f'No. of rows in Train Set: {len(train_dl.dataset)} \\n No. of rows in Test Set: {len(test_dl.dataset)}')"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No. of rows in Train Set: 235 \n",
            " No. of rows in Test Set: 116\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:251: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LVDORpHB4KFb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#define Neural Network\n",
        "model = MLP(34)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PvVfgxiW4MuH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#train the model\n",
        "train_model(train_dl, model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "auxCaP5b4P3f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "2fd81328-6c22-45c7-93b1-8caabf383d67"
      },
      "source": [
        "#model evaluation\n",
        "acc = evaluate_model(test_dl, model)\n",
        "print('Accuracy: %.3f' % acc)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.905\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GECq6vjf4TJs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "0b49fe74-ab40-4852-e7d9-46bd196a4f71"
      },
      "source": [
        "#make prediction for single data instance\n",
        "row = [1,0,0.99539,-0.05889,0.85243,0.02306,0.83398,-0.37708,1,0.03760,0.85243,-0.17755,0.59755,-0.44945,0.60536,-0.38223,0.84356,-0.38542,0.58212,-0.32192,0.56971,-0.29674,0.36946,-0.47357,0.56811,-0.51171,0.41078,-0.46168,0.21266,-0.34090,0.42267,-0.54487,0.18641,-0.45300]\n",
        "yhat = predict(row, model)\n",
        "print('Predicted: %.3f (class=%d)' % (yhat, yhat.round()))"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicted: 1.000 (class=1)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}